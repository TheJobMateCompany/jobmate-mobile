# üèóÔ∏è Architecture Technique - JobMate

Ce document d√©taille l'architecture logicielle de JobMate. Le syst√®me est con√ßu autour du paradigme de l'entonnoir (Acquisition ‚û°Ô∏è Tri ‚û°Ô∏è Enrichissement ‚û°Ô∏è Action) et utilise une approche orient√©e microservices (orchestr√©s de mani√®re pragmatique sur un serveur unique pour le MVP) afin de garantir la scalabilit√©, la r√©silience et la s√©paration des responsabilit√©s.

---

## 1. Vision Globale du Syst√®me

JobMate n'est pas une simple application CRUD. C'est un moteur de traitement de donn√©es asynchrone con√ßu pour minimiser les co√ªts d'appels aux LLMs (Intelligence Artificielle) en filtrant agressivement les donn√©es non pertinentes en amont.

1. **Acquisition :** Automatique (via des workers de scraping) ou Manuelle.
2. **Tri (Inbox) :** Zone tampon (`JobFeed`). L'utilisateur approuve ou rejette les offres (action √† tr√®s faible co√ªt de calcul).
3. **Enrichissement (AI) :** Le traitement co√ªteux (LLM, RAG) n'est d√©clench√© *que* sur les offres approuv√©es.
4. **Action (Suivi) :** Le CRM Kanban permettant le suivi des candidatures.

### Diagramme d'Architecture

```mermaid
graph TB
    subgraph Clients
        WEB["Web App (React)"]
        MOB["Mobile App (React Native)"]
    end
    subgraph Edge
        TRF["Traefik (Reverse Proxy / TLS)"]
    end
    subgraph Gateway["API Gateway ‚Äî Node.js :4000"]
        GQL["Apollo GraphQL /graphql\n(queries, mutations, uploadCV, parseCV)"]
        SSE["SSE Stream /events"]
    end
    subgraph Services
        PRF["Profile Service ‚Äî Python\ngRPC :9081 | HTTP :4001"]
        TRK["Tracker Service ‚Äî Go\ngRPC :9082 | HTTP /health :8082"]
        DSC["Discovery Service ‚Äî Python (autonome)\nCron interne + Scraper"]
        AIC["AI Coach ‚Äî Python\nRedis CMD_ANALYZE_JOB + CMD_PARSE_CV"]
    end
    subgraph Data
        PG[("PostgreSQL")]
        RDB[("Redis Pub/Sub")]
        CVU[("cv_uploads volume")]
    end
    WEB & MOB --> TRF
    TRF --> GQL & SSE
    GQL -->|"gRPC :9081  x-user-id metadata"| PRF
    GQL -->|"gRPC :9082  x-user-id metadata"| TRK
    GQL -->|"gRPC :9083  x-user-id metadata"| DSC
    GQL -->|"PUBLISH CMD_ANALYZE_JOB"| RDB
    GQL -->|"PUBLISH CMD_PARSE_CV"| RDB
    SSE -->|"SUBSCRIBE EVENT_*"| RDB
    PRF & TRK -->|SQL| PG
    PRF -->|"PDF write"| CVU
    DSC -->|"INSERT job_feed (PENDING)"| PG
    DSC -->|"PUBLISH EVENT_JOB_DISCOVERED"| RDB
    TRK -->|"PUBLISH EVENT_CARD_MOVED"| RDB
    RDB -->|CMD_ANALYZE_JOB| AIC
    RDB -->|CMD_PARSE_CV| AIC
    AIC -->|"UPDATE applications"| PG
    AIC -->|"UPDATE profiles (enrichissement CV)"| PG
    AIC -->|"PDF read"| CVU
    AIC -->|"PUBLISH EVENT_ANALYSIS_DONE / EVENT_CV_PARSED"| RDB
```

---

## 2. Stack Technologique

Le choix des technologies est dict√© par le principe du "Right tool for the right job" (Le bon outil pour le bon usage), tout en conservant une empreinte m√©moire ma√Ætris√©e.

| Composant | Technologie | Justification |
| :--- | :--- | :--- |
| **API Gateway / BFF** | Node.js (Apollo Server) | Point d'entr√©e GraphQL flexible. Excellente gestion de l'I/O asynchrone. |
| **Notifications Temps R√©el**| Server-Sent Events (SSE) | Rempla√ßant l√©ger des WebSockets pour du flux descendant (Server-to-Client). |
| **Profile & CV Service** | Python (FastAPI + asyncpg + pdfminer) | Gestion du profil √©tendu (skills, exp√©riences, certifications) et stockage des CVs PDF. |
| **Workers d'Acquisition** | Python (httpx + BeautifulSoup + APScheduler) | Scraping asynchrone des job boards, filtrage red flags, scheduleur int√©gr√©. |
| **Suivi Candidatures** | Go (Tracker Service) | Performances brutes et faible RAM pour le CRM Kanban (machine √† √©tats). |
| **Parsing CV & Analyse IA** | Python (pdfminer.six + OpenRouter LLM) | Extraction structur√©e du CV (pdfminer, sans binaire natif) + enrichissement LLM. |
| **Communication Interne** | gRPC (Gateway ‚Üí Profile :9081, Tracker :9082, Discovery :9083) & Redis Pub/Sub (Gateway ‚Üí AI Coach) | Z√©ro REST interne depuis la Gateway. Redis Pub/Sub pour le d√©couplage asynchrone vers l'AI Coach. |
| **Base de Donn√©es** | PostgreSQL | Robustesse relationnelle pour le CRM et les donn√©es utilisateurs. |

---

## 3. Architecture des Microservices

Bien que d√©ploy√©s sur un VPS unique (Monolithe Modulaire / Docker Compose), les services sont logiquement isol√©s.

### A. API Gateway (Node.js)
* **R√¥le :** Unique point d'entr√©e expos√© √† l'ext√©rieur (Frontends Web & Mobile). Toutes les communications Gateway ‚Üí Services internes sont **exclusivement gRPC** (z√©ro REST interne).
* **Endpoints HTTP/GraphQL expos√©s (via Traefik) :**
  * `POST /graphql` (Apollo GraphQL) : Toutes les mutations et requ√™tes de donn√©es (Login, Update Profile, ApproveJob, MoveCard, SearchConfig, Kanban, **uploadCV**).
  * `GET /events` (SSE) : Connexion longue dur√©e pour les notifications temps r√©el (ex: "Analyse IA termin√©e").
* **Clients gRPC internes (r√©seau Docker) :**
  * `userGrpc.js` ‚Üí `profile-service:9081` ‚Äî G√®re SearchConfigs et upload CV.
  * `trackerGrpc.js` ‚Üí `tracker-service:9082` ‚Äî G√®re le Kanban des candidatures.
  * `discoveryGrpc.js` ‚Üí `discovery-service:9083` ‚Äî G√®re le job feed et les statuts (SetJobStatus, AddJobByUrl, AddJobManually).

### B. Profile Service (Python)
* **R√¥le :** G√®re l'identit√© (register/login), les pr√©f√©rences de recherche (`SearchConfig`) et le profil √©tendu (skills, exp√©rience, √©ducation, certifications, CV).
* **Architecture duale (deux serveurs dans le m√™me process) :**
  * **gRPC sur le port 9081** (r√©seau Docker interne) ‚Äî Point d'entr√©e principal pour la Gateway. Contrat d√©fini dans `proto/user.proto`.
  * **HTTP sur le port 4001** ‚Äî Conserv√© pour `/health` (Traefik).
* **RPCs gRPC expos√©s :**
  * `GetProfile` ‚Äî Retourne le profil complet de l'utilisateur.
  * `UpdateProfile` ‚Äî Mise √† jour partielle (skills, exp√©rience, √©ducation, certifications, projets).
  * `GetSearchConfigs` ‚Äî Liste les configs de recherche actives.
  * `CreateSearchConfig` ‚Äî Cr√©e une nouvelle config.
  * `UpdateSearchConfig` ‚Äî Mise √† jour partielle.
  * `DeleteSearchConfig` ‚Äî D√©sactive une config (`is_active = false`).
  * `UploadCV` ‚Äî Re√ßoit le buffer PDF, le persiste sur le volume partag√© `cv_uploads` et met √† jour `profiles.cv_url`. Publie ensuite `CMD_PARSE_CV` sur Redis.
  * `ParseCV` ‚Äî Publie `CMD_PARSE_CV` sur Redis pour d√©clencher l'enrichissement AI.
* **Authentification :** L'identit√© de l'utilisateur est transmise via le champ `x-user-id` des m√©tadonn√©es gRPC (positionn√© par la Gateway apr√®s v√©rification du JWT).

### C. Discovery Service (Le Chasseur / Python)
* **R√¥le :** Moteur d'acquisition asynchrone enti√®rement autonome.
* **Important :** Ce service est **ind√©pendant** ‚Äî il peut recevoir des requ√™tes synchrones de la Gateway (ex: `GetJobFeed`, `SetJobStatus`, `AddJobByUrl`, `AddJobManually`) mais tourne principalement en t√¢che de fond.
* **Comportement :**
  * S'ex√©cute via un Job Scheduler interne (APScheduler).
  * R√©cup√®re les `SearchConfig` actives en base.
  * Scrape les job boards cibles de mani√®re asynchrone (httpx + BeautifulSoup).
  * **Filtre "Red Flag" :** Applique une exclusion stricte en amont.
  * Ins√®re les offres valid√©es dans `job_feed` (statut: `PENDING`) avec `title`, `description`, `source_url`, `raw_data`.
  * Expose un serveur **gRPC sur le port 9083** pour les appels synchrones de la Gateway.
* **RPCs gRPC expos√©s :**
  * `GetJobFeed` ‚Äî Liste les offres de l'utilisateur avec filtre `status` optionnel.
  * `SetJobStatus` ‚Äî Approuve ou rejette une offre (`APPROVED` | `REJECTED`).
  * `AddJobByUrl` ‚Äî Scrape une URL sp√©cifique et l'ins√®re en `PENDING`. Publie `EVENT_JOB_DISCOVERED`.
  * `AddJobManually` ‚Äî Ins√®re une offre via formulaire (nom entreprise, lieu, profil recherch√©, type de contrat, date de d√©but). Publie `EVENT_JOB_DISCOVERED`.

### D. AI Coach Service (Le Cerveau / Python)
* **R√¥le :** Analyse s√©mantique et g√©n√©ration de contenu assist√©e par LLM.
* **Triggers (multi-canal Redis) :**
  * `CMD_ANALYZE_JOB` ‚Äî D√©clench√© par la Gateway quand un utilisateur approuve une offre.
  * `CMD_PARSE_CV` ‚Äî D√©clench√© par la Gateway / Profile Service quand un CV est upload√©.
* **Actions (CMD_ANALYZE_JOB) :**
  * Calcule le `MatchScore`.
  * G√©n√®re les listes `Pros` (Points forts) et `Cons` (Points d'attention).
  * R√©dige la lettre de motivation et le contenu de CV optimis√© ATS.
  * Publie `EVENT_ANALYSIS_DONE` sur Redis ‚Üí SSE vers le client.
* **Actions (CMD_PARSE_CV) :**
  * Lit le PDF depuis le volume partag√© `cv_uploads` via `pdfminer.six`.
  * Appelle le LLM pour extraire : `skills`, `experience`, `education`, `certifications`, `projects`.
  * Met √† jour la table `profiles` avec les donn√©es structur√©es (PATCH partiel : ne remplace que les champs non vides).
  * Publie `EVENT_CV_PARSED` sur Redis ‚Üí SSE vers le client.

### E. Tracker Service (Le CRM Kanban / Go)
* **R√¥le :** G√®re le cycle de vie de la candidature post-approbation.
* **Transport :** Expose un serveur **gRPC sur le port 9082** (r√©seau Docker interne uniquement). Un serveur HTTP minimal sur le port 8082 est conserv√© exclusivement pour l'endpoint `/health` requis par Traefik.
* **Contrat gRPC :** D√©fini dans `proto/tracker.proto` (partag√© √† la racine du d√©p√¥t). Les stubs Go g√©n√©r√©s (`internal/pb/`) sont versionn√©s avec le code source et valid√©s en CI par `protoc`.
* **RPCs expos√©s :** `ListApplications`, `MoveCard`, `AddNote`, `RateApplication`.
* **Actions :** G√®re les transitions d'√©tat (To Apply ‚û°Ô∏è Applied ‚û°Ô∏è Interview ‚û°Ô∏è Hired) et pr√©pare l'archivage de la recherche en cas de succ√®s.

---

## 4. Sch√©ma de Donn√©es (PostgreSQL)

La base de donn√©es relationnelle garantit l'int√©grit√© du suivi candidat.



### Entit√©s Principales :

* **`Users`** : `id`, `email`, `password_hash`.
* **`Profiles`** : `user_id`, `full_name`, `status`, `skills_json`, `experience_json`, `projects_json`, `education_json`.
* **`SearchConfig`** (La "Recherche Enregistr√©e") :
  * `id`, `user_id`, `keywords` (Array), `red_flags` (Array)
  * `target_salary`, `remote_policy`, `location`, `cl_template_text` (Template Lettre de motivation).
* **`JobFeed`** (La "Waiting List" / Inbox) :
  * `id`, `user_id` (propri√©taire direct pour les offres manuelles), `search_config_id` (nullable), `raw_data` (JSON), `source_url`.
  * `title` (VARCHAR 512) et `description` (TEXT) : colonnes d√©normalis√©es depuis `raw_data` pour les requ√™tes SQL (tri, filtrage, recherche), √©vite l'extraction JSONB syst√©matique.
  * `status`: `PENDING` | `APPROVED` | `REJECTED`. *(Note: Cette table poss√®de un TTL pour nettoyage automatique).*
  * `is_manual`: `TRUE` si l'offre a √©t√© ajout√©e via URL ou formulaire manuel par l'utilisateur (et non scrap√©e automatiquement).
  * Colonnes sp√©cifiques aux offres manuelles : `company_name`, `company_description`, `why_us`.
* **`Profiles`** (suite) :
  * `skills_json`, `experience_json`, `education_json`, `certifications_json`, `projects_json` (JSONB).
  * `cv_url` ‚Äî chemin relatif du CV PDF sur le volume partag√© `cv_uploads`.
* **`Applications`** (Les candidatures actives) :
  * `id`, `user_id`, `job_feed_id`
  * `current_status` (Enum: `TO_APPLY`, `APPLIED`, `INTERVIEW`, `OFFER`, `REJECTED`, `HIRED`).
  * `ai_analysis` (JSON: Score, Pros, Cons, Suggested_CV_Content).
  * `generated_cover_letter` (Text).
  * `user_notes` (Text), `user_rating` (Int).
  * `relance_at` (Timestamp) ‚Äî date de relance planifi√©e.
  * `history_log` (JSON: Audit trail des changements de statut).

---

## 5. Le Flow de Communication (Exemple Asynchrone)

Voici comment les services interagissent lors de l'action cl√© du syst√®me : **L'approbation d'une offre**.

1. **User** clique sur "Approuver" dans le frontend.
2. **Frontend** envoie une mutation GraphQL `approveJob(id)` √† l'**API Gateway**.
3. **API Gateway** met √† jour Postgres (`JobFeed.status = APPROVED` et cr√©e l'entr√©e `Applications`).
4. **API Gateway** publie le message asynchrone `CMD_ANALYZE_JOB` avec l'ID de la candidature sur **Redis Pub/Sub**.
5. L'**API Gateway** r√©pond imm√©diatement au client (HTTP 200). Le frontend affiche un √©tat "En cours d'analyse...".
6. Le **AI Coach Service (Python)** capte le message Redis, effectue son traitement lourd (appels LLM), met √† jour la table `applications` dans Postgres, puis publie l'√©v√©nement `EVENT_ANALYSIS_DONE` sur Redis.
7. L'**API Gateway** capte l'√©v√©nement de fin via Redis et pousse la notification au Frontend via le canal **SSE** ouvert.
8. Le **Frontend** met √† jour la carte instantan√©ment avec les r√©sultats de l'IA.

**Flux parall√®le ‚Äî Enrichissement CV (CMD_PARSE_CV) :**

1. **User** uploade un PDF via la mutation `uploadCV`.
2. **Profile Service** persiste le fichier sur le volume `cv_uploads`, met √† jour `profiles.cv_url`, publie `CMD_PARSE_CV {userId, cvUrl}` sur Redis.
3. L'**API Gateway** r√©pond imm√©diatement (URL du CV).
4. L'**AI Coach** re√ßoit `CMD_PARSE_CV`, extrait le texte via `pdfminer.six`, appelle le LLM, enrichit la table `profiles`.
5. L'**AI Coach** publie `EVENT_CV_PARSED` ‚Üí Gateway SSE ‚Üí client.
